\chapter{Conclusions}
In this paper we have compared the ability of ILP systems to learn the rules of a game from observed gameplay in the IGGP framework on a range of training datasets. Primarily three ILP systems have been trained on random and intelligent gameplay as generated by the Sancho system. The generated hypotheses of the learners have been tested on random and intelligent gameplay from the same distributions as the training data. Differences in the effectiveness of the learned programs in correctly classifying legal and illegal gameplay were observed however there was not enough statistical significance in the results to disprove the null hypothesis. The systems were also trained on a mixture of optimal and random traces with similar results.

To test the significance of the size of the training dataset on the ability of the ILP systems to learn the systems were trained on varying numbers of game playouts. It was a training dataset of above 16 game traces had little effect on the ability to learn of the systems tested. 

\subsubsection{Future work}

\textbf{What is intelligence?} In this paper we use the concept of intelligence in relation to game traces without formally defining it. Future work could supply a framework with which we can define the intelligence of gameplay generated.

\textbf{ILP systems} In this paper we only test on three ILP systems, it is clear a more representative result could be obtained by testing on more systems. Techniques such as probabilistic\cite{Bellodi/Probablistic,Raedt/Probabalistic} and interactive\cite{Raedt/Interactive} learning are not used by any of the systems tested here. ILASP is the only system designed to handle noisy data\cite{MarkLaw/ILASP2i}, it would be interesting to try others with this approach\cite{Oblak/Noise,Evans/Noise}. The systems used also have many customisable settings for example Metagols metarules which have major implications for the programs learnt\cite{Cropper/Metarules}. Aleph has many different search methods on the hypothesis space many of which may yield better results than the default algorithm used in this paper.

\textbf{Generating traces} Whilst Sancho generates good examples of intelligent play it would be interesting to see traces generated by other general game playing methods\cite{Park/GGPAdvances,Kowalski/GGP}. For some games there exists a provably optimal set of moves in some cases such as for eight puzzle Sancho generates these moves (see section \ref{sec:sancho}) however it does not for all such games\cite{Schaeffer/Checkers}. Future research could compare the effects on the learned hypotheses when trained on optimal data. It may also be more insightful to look at the difference between human generated data and random or optimal.

\textbf{Other machine learning systems} There exists a huge variety of machine learning systems other than ILP. It is possible some of these may exhibit more of a bias toward one of the training sets. Testing a neural network or genetic algorithm based approach may provide insightful results.

\textbf{Intelligent verses random in other contexts} There are plenty of other domains other than game playing in which datasets can be considered intelligent or random. An example of this might be training a car to drive where you could train it on different quality levels of driving or training a facial recognition system on poor or high quality photos. These would prove an interesting area to study.


