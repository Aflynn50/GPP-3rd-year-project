\chapter{Related work}

\section{General Game Playing}

General Game Playing (GGP) is a framework for evaluating an agent's general intelligence across a wide range of tasks \cite{Cropper/IGGP,Genesereth/GGPOverview}. The agents accept declarative descriptions of arbitrary games at run time and use the descriptions to play those games effectively. All the games are finite, discrete, deterministic multi-player games of complete information \cite{GDL_Spec}. The games in the GGP competition game set vary in number of players, dimensions and complexity. For example games such as \textit{rock paper scissors} have 0 dimensions and only 10 rules in the given GGP rule set, more complex games such as \textit{checkers} has 52 rules and are 2 dimensional. There are also single player games such as \textit{eight puzzle} or \textit{fizz buzz}.

The agents play games selected at random. They are sent a listing of the rules described in the Game Description Language (GDL). GDL is a language based on first order logic (section \ref{sec:GDL}). Matches take place through an online framework called the Gamemaster which arbitrates the competition  \cite{Genesereth/GGPOverview}.

In 2005 an annual International General Game Playing Competition (IGGPC) was set up \cite{Kowalski/GGP}. Each year hopeful participants pit GGP agents against one another to determine the most effective system. The competitors take part in a series of rounds of increasing complexity. The agent that wins the most games in these rounds is declared victorious. The 2014 winner Sancho is used in this paper to generate traces of intelligent game play for the IGGP task.

The game descriptions written in GDL used in the GGP competition can be used as example rule sets for systems in Inductive General Game Playing (IGGP) as the output the learners would ideally generate. The descriptions of the games used in GGP are not necessarily minimal so it is possible that an ILP system could generate a more concise rule set than the GGP descriptions.

\subsection{Game Description Language}\label{sec:GDL}
Game Description Language (GDL) is the formal language used in the GGP competition to specify the rules of the games \cite{GDL_Spec}. The language is based off a logical programming language \textit{datalog}, a subset of Prolog. To understand the semantics of GDL it helps to first cover logic programming as a field of study.
\subsubsection{Logic Programming}
Logic programming is a programming paradigm based on formal logic. Programs are made up of facts and rules. Rules are made up of two parts: the head and the body. They can be read as logical implications where the conjunction of all the elements in the body imply the head. The syntax is different for different logical programming languages but the head is usually written before the body in reverse implication. For example \texttt{a :- b,c}. A fact is simply a rule without a body, that is, a statement that is taken as true. The interpreter takes logical statements as queries and returns whether they are true or false. If there are free variables in the query the interpreter assigns them values for which the query is true. Logical programming is good for symbolic non-numeric computation \cite{Bratko}. It is well suited to solving problems that involve well defined objects and relations between them, such as a GGP game.
\subsubsection{Usefulness of GDL}
The game description language was designed specifically to represent finite, discrete, deterministic multi-player games of complete information. The language is based on \textit{Datalog} and the property of any question of logical entailment being decidable is retained.

The games are defined in terms of a set of true facts capturing the information needed to give the following predicates:
\begin{itemize}
\item The initial game state
\item The goal state
\item The terminal state
\end{itemize}
In addition, logical rules are used to describe the following:
\begin{itemize}
\item The legal moves for a given player and state
\item The next state for a given player state and move
\item The termination and goal conditions
\end{itemize}

The GDL language is an extension of \textit{Datalog$^{\neg}$}, that is \textit{Datalog} with stratified negation \cite{GDL_Spec}. \textit{Datalog} allows only universally quantified rules consisting of a conjunction of positive atoms that imply a single atom. \textit{Datalog$^{\neg}$} allows for negative as well as positive atoms \cite{Alice/Foundations}. GDL also allows for some functional symbols, that is predicates containing other predicates however it restricts to keep the finite model property that is inherent to \textit{Datalog} \cite{GDL_Spec}.

In GDL variables are written with the symbol \texttt{?} before them and rules are written starting with \verb|=>| followed by the head followed by the body predicates which are interpreted as a conjunction. All rules are universally quantified. For example
\[\texttt{(<= (next (cell ?x ?y ?player)) (does ?player (mark ?x ?y)))}\]
in first order logic this would be written
\[\forall x. \forall y. \forall player. does(player,(mark(x,y))) \rightarrow cell(x,y,player)\]
GDL also reserves certain words as listed in table \ref{tab:GDL}
\begin{center}
	\begin{table}
	\begin{tabular}{| l | l |}
		\hline
		\texttt{true(?f)} & Atom \texttt{?f} is true in the current game state \\ \hline
		\texttt{does(?r,?m)} & Player \texttt{?r} performs action \texttt{?m} in the current state \\ \hline
		\texttt{next(?f)} & Atom \texttt{?f} will be true in the next game state \\ \hline
		\texttt{legal(?r,?m)} & Action \texttt{?m} is a legal move for player \texttt{?r} in the current game state\\ \hline
		\texttt{goal(?r,?n)} & Player \texttt{?r} performs action \texttt{?m} in the current game state\\ \hline
		\texttt{terminal} & The current state is terminal\\ \hline
		\texttt{init(?f)} & Atom \texttt{?f} is true in the initial game state\\ \hline
		\texttt{role(?n)} & The Constant \texttt{?n} denotes a player\\ \hline
		\texttt{distinct(?x,?y)} & \texttt{?x} and \texttt{?y} are syntactically different\\
		\hline

	\end{tabular}
	\caption{The reserved predicates in GDL}
\label{tab:GDL}
\end{table}

\end{center}


In the IGGP problem (section \ref{sec:IGGP}) the given task is to generate the rules to predict the values for the goal, the next state, the legal states and the terminal predicates.


\section{Inductive General Game Playing}\label{sec:IGGP}
The Inductive General Game Playing (IGGP) problem is an inversion of the GGP problem. Rather than using game rules to generate gameplay the learner must learn the rules of the game from observations of game play. The learner is given a set of game traces and is tasked with using them to induce (learn) the rules of the game that could have produced the traces \cite{Cropper/IGGP}. IGGP was designed as a way of benchmarking machine learning systems.

The definition of task itself is based on the Inductive Logic Programming problem.

\subsection{Inductive Logic Programming}\label{sec:ILP}
Inductive Logic Programming (ILP) is a form of machine learning that uses logic programming to represent examples, background knowledge, and learned programs \cite{Cropper/EfficientLearning}. To learn the program is supplied with positive examples, negative examples and the background knowledge. In the general inductive setting we are provided with three languages.
\begin{itemize}
\item $\mathcal{L}_O$: the language of observations (positive and negative examples)
\item $\mathcal{L}_B$: the language of background knowledge
\item $\mathcal{L}_H$: the language of hypotheses
\end{itemize}
The general inductive problem is as follows: given a set of positive examples $E^+ \subseteq \mathcal{L}_O$, negative examples $E^- \subseteq \mathcal{L}_O$ and  background knowledge $B \subseteq \mathcal{L}_B$ find an hypothesis $H \in \mathcal{L}_H$ such that 
\[B \cup H \models E^+ \wedge B \cup H \not\models E^-\]
\cite{Muggleton/ILP}
That is that the generated hypothesis and the background knowledge imply the positive examples and do not imply the negative examples.


\subsection{Back to IGGP}

In IGGP we also have the idea of background knowledge and positive or negative observations. The task itself is closely based on the ILP problem and is described in chapter \ref{ch:IGGP}. The games used for the IGGP problem are taken from the IGGP dataset. It is a collection of 50 games, specified in GDL. The purpose of this database is to standardise the set of games used in the IGGP problem to allow for results to be easily compared. It is the set of games that this paper is based on.
A mechanism is also provided by the authors to turn these GDL game descriptions in the set into new IGGP tasks. This method plays the games randomly to generate the observations. In this paper we modify the mechanism to generate optimal game traces.


\section{ILP systems used}
We use three ILP systems to compare the effects of different learning data, Metagol, Aleph and ILASP. There are many approaches to the ILP problem \cite{Svetla/ILPOverview,Cropper/NewIdeas}. The three systems here all represent different approaches to the problem but certainly do not give a full representation of the techniques available.
\subsection{Metagol}
The Metagol ILP system is a meta-interpreter for Prolog, that is, it is written in the same language is evaluates \cite{Cropper/Thesis,Rolf/Metagol,Metagol/Github}. Metagol takes positive and negative examples, background knowledge and meta-rules. Meta rules are specific to Metagol. They determine the shape of the induced rules and are used to guide the search for a hypothesis. An example of a metarule is the \textit{chain} rule \[P(A,B) \leftarrow Q(A,C),R(C,B)\] The letters $P$, $Q$ and $R$ represent existentially quantified second order variables, $A$, $B$ and $C$ are regular first order variables. When trying to induce rules the second order variables are substituted for predicates from the background knowledge or the hypothesis itself. To illustrate this consider a metarule being applied when learning the predicate \textit{last(A,B)} where a is a list and b is the last element in it. Given the positive example
\begin{minted}{Prolog}
last([a,l,g,o,r,i,t,h,m],m).
\end{minted}

As well as the background predicates \textit{reverse/2} and \textit{head/2} the chain rule might be used to derive the rule
\begin{minted}{Prolog}
last(A,B) :- reverse(A,C), head(C,B)
\end{minted}

\begin{enumerate}
\item Select a positive example (an atom) to generalise. If none exists, stop, otherwise proceed to the next step.
\item Try to prove an atom using background knowledge by delegating the proof to Prolog. If successful, go to step 1, otherwise proceed to the next step.
\item Try to unify the atom with the head of a metarule and either choose predicates from the background knowledge that imply the head to fill the body. Try proving the body predicate, if it cannot be proved try different predicate in the background knowledge\footnote{To prove the body predicate the whole procedure is called again with the body predicates as the positive examples. For example if we had \texttt{last([a,b],b)} as our positive example and have tried to use the chain metarule to to prove it with reverse and head we would then call the whole procedure again with the positive examples as \texttt{[reverse([a,b],C),head(C,b)]} if this was successful then we continue, otherwise we try different predicates}. If no predicate can be found that proves the positive example then try adding a new invented predicate and attempt to prove this\footnote{For example we might replace head with an invented predicate in the previous footnote example}.
\item Once you find a metarule substitution that works add it to the program and move to the next atom
\end{enumerate}


The end hypothesis is all the metarule substitutions. It is then checked that the negative atoms are not implied by the hypothesis, if they are a new one is generated. When the hypothesis is combined with the background knowledge the positive examples, but not the negative examples, are implied.

The choice of metarules determines the structure of the hypothesis. Different choices of metarules will allow different hypotheses to be generated. Deciding which metarules to use for a given task is an unsolved problem  \cite{Cropper/Thesis}. For this task a set of 9 derivationally irreducible metarules are used which remain consistent across all tasks.

\subsection{Aleph}\label{sec:aleph}

Aleph is a Prolog variant of the ILP system Progol  \cite{Muggleton/Aleph}. As input, like any other ILP system, Aleph takes positive and negative examples represented as a set of facts along with the background knowledge. It also requires \textit{mode declarations} and \textit{determinations} which are specific to Aleph. Mode declarations specify the type of the inputs and outputs of each predicate used e.g. \texttt{plus(+integer,+integer,-integer)} where \texttt{+} signifies an input and \texttt{-} an output.
Determinations specify which predicates can go in the body of a hypothesis. These determinations take the form of pairs of predicates, the first being the head of the clause and the second a predicate that can appear in its body.

For each predicate we would like to learn in the IGGP problem we give Aleph the determinations consisting of every target predicate (next,goal and legal) paired with every background predicate (which are specific to each game). Luckily there has been some work to induce mode declarations from the determinations  \cite{McCreath/Meta-extraction} so we do not need to come up with our own mode declarations.

A basic outline of the Aleph algorithm is taken from the aleph website \footnote{http://www.cs.ox.ac.uk/activities/programinduction/Aleph/aleph.html accessed 26/03/2020}:
\begin{enumerate}
\item Select an example to be generalised. If none exist, stop, otherwise proceed to the
next step.
\item Construct the most specific clause (also known as the bottom clause  \cite{Muggleton/Aleph}) that entails
the example selected and is within language restrictions provided.
\item Search for a clause more general than the bottom clause. This step is done by searching for some subset of the literals in the bottom clause that has the 'best' score.
\item The clause with the best score is added to the current theory and all the examples
made redundant are removed. Return to step 1.
\end{enumerate}

Mode declarations and determinations are used in step 2 of this procedure to bound the hypothesis space. Only predicates that are mentioned in the determinations of the hypothesis and are of the correct type are tried. The bottom clause constructed is the most specific clause that entails the example. Therefore a clause with the same head and any subset of the predicates of the body will be more general than the bottom clause. Aleph only considers these generalisations of this bottom clause.

The search space is therefore bounded by $2^n$ with $n$ being the number of predicates in the bottom clause. By default Aleph preforms a bounded breath first search on all the possible rules, enumerating shorter clauses before longer clauses. The search is bounded by several parameters such as maximum clause size and maximum proof depth. For this paper we will use Aleph with the default settings.

\subsection{ILASP}

ILASP is an ILP system based on Answer Set Programming (ASP). An introduction to ASP can be found here  \cite{Corapi/ASP}. ILASP uses a subset of ASP that is defined in these papers  \cite{ILASP-Manuel,MarkLaw/OG-ILASP,MarkLaw/Thesis} The ILASP process effectively generates all possible rules of a certain length, turns the problem into an ASP problem that adds a predicate to each rule allowing it to be active or inactive. It then uses the ASP solver \textit{clingo}  \cite{Clingo}  to check which rules should be active if the program is to be consistent with the positive and the negation of the negative examples  \cite{MarkLaw/OG-ILASP,MarkLaw/Thesis}. In this paper we use a version of ILASP based on ILASP2i  \cite{MarkLaw/ILASP2i} which was developed with the IGGP problem in mind \cite{Cropper/IGGP}. As one input ILASP takes a hypothesis search space, i.e. the set of all hypotheses to be considered. This is constructed using the type signatures given for each problem that are provided in the IGGP dataset.

An ILASP task is defined as a tuple $T = \langle B,S_M,E^+E^-\rangle$ where $B$ is the background knowledge, $S_M$ is the hypothesis space, and $E^+$ and $E^-$ are the positive and negative examples. The ILASP procedure is given in algorithm \ref{alg:ILASP}.
\begin{algorithm}[H]\label{alg:ILASP}
    \SetAlgoLined
    $n$ = 0\;
    solutions = []\;
    \While{solutions.empty}{
        $S^N$ = all possible hypotheses of length $N$ from $S_M$ \;
        $ns$ = all subsets of $S^N$ that imply $E^-$ (Using an ASP solver)\;
        $vs$ = the set of rules that for each set of rules in $ns$ imply false if exactly those rules are active\;
        solutions = all subsets of $S^N$ that imply $E^+$ and satisfy $vs$ (using asp solver)\;
        $n$ = $n$ + 1\;
    }
    \caption{ILASP outline}
\end{algorithm}

The approaches used by ILASP have proved to be well suited to the IGGP task  \cite{Cropper/IGGP}.