% \chapter{Logical setting}
\chapter{IGGP problem}
\label{ch:IGGP}

The IGGP problem is defined in the 2019 paper Inductive General Game Playing \cite{Cropper/IGGP}. Much like the problem of ILP described in section \ref{sec:ILP} the problem setting consists of examples about the truth or falsity of a formula $F$ and a hypothesis $H$ which covers $F$ if $H$ entails $F$. We assume the languages of:
\begin{itemize}
\item $\mathscr{E}$ the language of examples (observations)
\item $\mathscr{B}$ the language of background knowledge
\item $\mathscr{H}$ the language of hypotheses
\end{itemize} 
Each of these languages can be see as a subset of those described in \ref{sec:ILP}. These languages are made up only of function free ground atoms. In our experiments we transform data from the GDL descriptions of games in the IGGP dataset and transform it into the languages of $\mathscr{B}$ and $\mathscr{E}$. GDL allows for functions (predicates nested in one another) in rules albeit in a restricted form. For example any atom appearing inside a \texttt{true} predicate such as \texttt{true(count(9))}. We flatten all of these to single, non nested predicates, i.e. \verb|true_count(9)|. This is needed as not all ILP systems support function symbols. We can therefore assume that both $\mathscr{E}$ and $\mathscr{B}$ are function-free. The language of hypotheses $\mathscr{H}$ can be assumed to consist of datalog programs with stratified negation as described here\cite{Kenneth}. Stratified negation is not necessary but in practice allows significantly more concise programs, and thus often makes the learning task computationally easier. We first define an IGGP \textit{input} then use it to define the IGGP \textit{problem}. The IGGP input needs to capture the idea of a set of observations about a game. The input is based on the general input for the Logical induction problem of section \ref{sec:ILP} since this is a sub problem of it.

\textbf{The IGGP Input:} An input $\Delta$ is a set of triples $\{(B_i,E_i^+,E_i^-)\}_m^{i=1}$ where
\begin{itemize}
\item $B_i \subset \mathscr{B}$ represents background knowledge
\item $E_i^+ \subseteq \mathscr{E}$ and $E_i^- \subseteq \mathscr{E}$ represent positive and negative examples respectively
\end{itemize}
The IGGP input composes the IGGP problem as follows:

\textbf{The IGGP Problem:} Given an IGGP input $\Delta$, the IGGP problem is to return a hypothesis $H \in \mathscr{H}$ such that for all $(B_i,E_i^+,E_i^-) \in \Delta$ it holds that $H \cup B_i \models E_i^+$ and
$H \cup B_i \not\models E_i^-$.


\subsubsection{Problem Setting}
\af{this section probably needs improving}

Let the accuracy of a set $I$ of ILP systems be defined as the mean of the percentage accuracy of each of them when tested on a given set of examples.

Given an set of ILP systems $I$, for what selection of game traces $\Delta$ combined from an optimal gameplay distribution and a random gameplay distribution are the systems most accurate when solving the IGGP problem. The accuracy of $I$ when solving the IGGP problem will be tested by evaluating each $i \in I$ with data taken from a 50/50 combination of both optimal and random distributions.

Also given a set of ILP systems $I$, and a gameplay distribution $G$ how does the number of training samples $|\Delta|$ taken from $G$ affect the accuracy of the hypothesis $H$ for each $i \in I$ when tested on $G$.

