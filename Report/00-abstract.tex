\begin{abstract}

%\ac{GGP is ....}
General Game Playing (GGP) is a framework in which an artificial intelligence program is required to play a variety of games successfully. The framework includes repositories of game descriptions written in a logic programming language. These game descriptions can be used separately as an interesting Inductive Logic Programming problem.	
%\ac{more, why is it interesting?}

%\ac{IGGP is ....}
The Inductive General Game Playing (IGGP) problem challenges ILP systems to learn these GGP game rules by watching the game being played. This challenge motivates investigation into ways to better induce general rules from specific examples and provides a good test bed for existing ILP systems.
%\ac{more, why is it interesting?}

%\ac{However, a limitation of existing work is ....}	
Existing work on IGGP has always assumed that the game player being observed makes random moves. This is not representative of how a human learns to play a game, to learn to play chess we watch someone who is playing to win.
%\ac{more, why is it interesting?}

%\ac{To address this limitation we, .....}
To address this limitation, in this paper we analyse the effect of using optimal verses random gameplay traces as well as the effect of varying the number of traces in the training set.

We use the General Game Playing competition winner in 2014, Sancho, to generate optimal game traces for a large number of games and the systems, Metagol, Aleph and ILASP are trained and tested with combinations of optimal and random data.
%\ac{Write with an active voice 'We use Sacho ...'}

%\ac{Our results show ....}

%\ac{The implication of this work is ....}



% When learning programs in Inductive Logic Programming (ILP) optimisations to the dataset used to train the systems can often be as effective as improvements to the systems themselves.


\end{abstract}