\documentclass[a4paper,10pt]{report}
\usepackage{float,graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{minted}
\usepackage{mathrsfs}
\usepackage{pgfplots}
\usepackage{mdframed}
\usepackage[lined,boxruled]{algorithm2e}\usepackage{color}
\usepackage[english]{babel}

\newcommand{\ac}[1]{\textcolor{red}{AC: #1}}
\newcommand{\af}[1]{\textcolor{blue}{AF: #1}}

\pgfplotsset{width=10cm,compat=1.9}
\usemintedstyle{friendly}
\BeforeBeginEnvironment{minted}{\begin{mdframed}}
\AfterEndEnvironment{minted}{\end{mdframed}}
\begin{document}
\title{\Large{\textbf{Inducing game rules from varying quality game play}}}
% \title{\Large{\textbf{Inductive general game playing with varying quality game play}}}
\author{Alastair Flynn}
\maketitle

\input{00-abstract}
\input{01-intro}
\input{02-related}
\input{03-logical-setting}



\section{Sancho}
To generate optimal gameplay we decided that the best approach was to use a previous winner of the GGP competition. Since the aim of the competition is to find the program that performs best at the set of games used in the IGGP problem we conclude that there is no better way to generate a comprehensive set of game traces. The winner of the 2014 GGP competition 'Sancho' was selected \footnote{http://ggp.stanford.edu/iggpc/winners.php accessed on 12/03/2020} since they are the most recent winner to have published their code \footnote{http://sanchoggp.github.io/sancho-ggp/ access 12/03/2020}. Some small modifications to the information logged by the game server are made but otherwise the code is unchanged.

The core of Sancho is the Monte Carlo tree search (MCTS) algorithm.

\subsubsection{Monte Carlo Tree Search}
Given a game state the basic MCTS will return the most promising next move. The algorithm achives this by simulating random playouts of the game many times. The technique was developed for computer Go but has since been applied to play a wide range of games effectively including board games and video games\cite{Silver/MCTS}\cite{Chaslot/MCTS}.

The use of random simulation to evaluate game states is a powerful tool. Information about the game such as heuristics for evaluating non terminal states are not needed at all, the rules of the game are enough on their own. In the case of the GGP problem this is ideal. The rules of the game are only revealed shortly before the game is played meaning deriving effective heuristics is a hard problem.

In our case all games being played are sequential, finite and discrete so we only need to consider MCTS for this case.
% say why it is good for this

% possibly put in a diagram of game tree
The MCTS is a tree search algorithm, the tree being searched is the game tree. A game tree being a tree made up of nodes representing states of the game and the children of each node being all the states that can be moved to from that state. The leaves of this tree are the terminal states. The search is a sequence of traversals of the game tree. A traversal is a path that starts at the root node and continues down until it reaches a node that has at least one unvisited child. One of these unvisited children are then chosen to be the start state for a simulation of the rest of the game. The simulation chooses random moves, playing the game out to a terminal state. The result of the simulation is propagated back from the node it started at all the way to the root node to update statistics attached to each node. These statistics are used to choose future paths to traverse so more promising moves are investigated more.

Exactly how the tree search algorithm chooses new nodes to simulate is where the complexity lies. The node chosen by traversal of the tree should strike a balance between exploiting promising nodes and exploring nodes with few simulations. The Upper Confidence Bound for trees algorithm was designed to do exactly this\cite{Kocsis/UCT}. The algorithm chooses a child node for each state based on the UTC formula. The formulae can be written as: \[UTC(v_i) = \frac{Q(v_i)}{N(v_i)} + c\sqrt{\frac{ln(N(v_i))}{N(v_i)}}\] Where we have:
\begin{itemize}
\item $v_i$ is node $v$ after move $i$
\item $Q(v)$ is the number of winning simulations that have taken place below it
\item $N(v)$ is the number of simulations that have taken place below it
\end{itemize}
The function is the sum of two components. $\frac{Q(v_i)}{N(v_i)}$ is called the exploitation component. It is a ratio of winning to loosing simulation that resulted from making this move. This encourages traversal of promising nodes that have a high win rate. However, if only this factor was used the algorithm would quickly find a winning node and only explore that hence we need a second component: the exploration factor. $c\sqrt{\frac{ln(N(v_i))}{N(v_i)}}$ favours nodes that have not yet been explored. The value $c$ is a constant that balances the two components, it can be adjusted depending on the use case.

Sancho makes a few modifications to MCTS\footnote{https://sanchoggp.blogspot.com/2014/05/what-is-sancho.html accessed on 15/03/2020}, the main one being adding of heuristics. The tree is also replaced with a more general graph which allows for transitions between lines of play without duplication of states. There are other modifications to increase efficiency.

In GGP matches a period of time before the match is given in which to do pre match calculations. Sancho uses this period to derive basic heuristics and optimise the value of $c$ in the formulae. A heuristic should take a game state or move and return a value based on how promising that state or move is in relation to the goal state. To take the heuristics into account when choosing the next state to explore each node (state) $v$ is seeded with a heuristic value on creation.

The identification of possible heuristics takes place in two stages. The first of these is static analysis of the game rules. This static analysis identifies possible heuristics that can be applied to the current game. These include things like piece capture: if certain rules indicate capture of a piece these can be selected against, or numeric quantity detection: a number in the state acts as a heuristic (like number of coins a player has). The second stage is simulation of the game. Many (possibly tens of thousands) of full simulations of the game are run. After the simulations are complete a correlation coefficient is calculated between each candidate heuristic's observed values and the eventual score achieved in the game. Those heuristics that show correlation above a fixed threshold are then enabled, and will be used during play.

\subsection{Other aspects of Sancho}
Monte carlo simulations are used for a large number of the games available however Sancho identifies games that can be solved more efficiently in other ways. Any single player game in the GGP dataset can be analyised using puzzle solving techniques. 
\subsubsection{Puzzle Solving}
A single player game in the GGP dataset is neciserally a deterministic game of complete information. This is due to the constraints of the Game Description Language, it is not possible to express anything more. This gives the constraint that any solution found in a playout of the game will always remain valid since the game is completely deterministic. Sancho identifies these single player games and attempts to derive huristics. Where an obviouse goal state exsists a distance metric such as the hamming distance between two states can be applied. A* search can then be used to find optimal solutions. For some games, such as eight puzzle the hamming distance is an admisable huristic so sancho finds an optimal solution.

Sancho also does static analysis of the game rules. It determins game predicates that if true mean the goal will never be true in any proceding state as well as predicates that garentee that the goal will be true in a future state. An example of this is a game such as untwisty corridor (the game is effecitvly a maze where if you immidiatly lose if you step off a 'safe' path). If the safe path is left then the goal can never be reached so any state not on the safe path is avoided.

\af{Talk about why this makes sancho good for this task}
\chapter{ILP systems used}
We use three ILP systems to compare the effects of different learning data, Metagol, Aleph and ILASP. All three systems use different approaches the ILP problem.
\section{Metagol}
The Metagol ILP system is a meta-interpreter for Prolog, that is, it is written in the same language is evaluates. Metagol takes positive and negative examples, background knowledge and meta-rules. Meta rules are specific to Metagol. They determin the shape of the induced rules and are used to guide the search for a hypothesis. An example of a metarule is the \texttt{chain} rule \[P(A,B) \leftarrow Q(A,C),R(C,B)\] The letters P, Q and R represent existentially quantified second order variables, A, B and C are regular Prolog variables. When trying to induce rules the second order variables are substituted for predicates from the background knowledge or the hypothesis itself. To illustrate this consider a metarule being applied when learning the predicate \textit{last(A,B)} where a is a list and b is the last element in it. Given the positive example 
\begin{minted}{Prolog}
last([a,l,g,o,r,i,t,h,m],m).
\end{minted}  

As well as the background predicates \textit{reverse/2} and \textit{head/2} the chain rule might be used to derive the rule 
\begin{minted}{Prolog}
last(A,B) :- reverse(A,C), head(C,B)
\end{minted}


\cite{Andrew/ILP-review}\cite{Rolf/Metagol}\cite{Metagol/Github}
\begin{enumerate}
\item Select a positive example (an atom) to generalise. If none exists, stop, otherwise proceed to the next step.
\item Try to prove an atom using background knowledge by delegating the proof to Prolog. If successful, go to step 1, otherwise proceed to the next step.
\item Try to unify the atom with the head of a metarule and either choose predicates from the background knowledge that imply the head to fill the body. Try proving the body predicate, if it cannot be proved try different BK\footnote{To prove the body predicate the whole procedure is called again with the body predicates as the positive examples. For example if we had \texttt{last([a,b],b)} as our positive example and have tried to use the chain metarule to with reverse and head we would then call the whole procedure again with the positive examples as [reverse([a,b], C),head(C,b)] if this was successful then we continue, otherwise we try different predicates}. If no BK can be found that prove the positive example then try adding a new invented predicate and attempt to prove this\footnote{For example we might replace head with an invented predicate in the previous footnote example}.
\item Once you find a metarule substitution that works add it to the program and move to the next atom
\end{enumerate}


The end hypothesis is all the metarule substitutions. It is the checked that the negative atoms are not implied by the hypothesis, if they are a new one is generated. When the hypothesis is combined with the background knowledge the positive examples, but not the negative examples, are implied.

The choice of metarules determines the structure of the hypothesis. Different choice of metarules will allow different hypotheses to be generated. Deciding which metarules to use for a given task is an unsolved problem \cite{Cropper/Thesis}. For this task a set of 9 derivationally irreducible metarules are used which remain consistent across all tasks.
\section{ALEPH}
Aleph is an Prolog variant of the ILP system Progol \cite{Muggleton/Aleph}. As input, like any other ILP system, Aleph takes positive and negative examples represented as a set of facts along with the background knowledge. It also requires \textit{mode declarations} and \textit{determinations} which are specific to Aleph. Mode declarations specify the type of the inputs and outputs of each predicate used e.g. \texttt{plus(+integer,+integer,-integer)} where \texttt{+} signifies an input and \texttt{-} an output.
Determinations specify which predicates can go in the body of a hypothesis. These determinations take the form of pairs of predicates, the first being the head of the clause and the second a predicate that can appear in its body.

For each predicate we would like to learn in the IGGP problem we give Aleph the determinations consisting of every target predicate (next,goal and legal) paired with every background predicate (which are specific to each game). Luckily there has been some work to induce mode declarations from the determinations \cite{McCreath/Meta-extraction} so we do not need to come up with our own mode declarations.

A basic outline of the Aleph algorithm is taken from the aleph website \footnote{http://www.cs.ox.ac.uk/activities/programinduction/Aleph/aleph.html accessed 26/03/2020}:
\begin{enumerate}
\item Select an example to be generalised. If none exist, stop, otherwise proceed to the
next step.
\item Construct the most specific clause (also known as the bottom clause \cite{Muggleton/Aleph}) that entails
the example selected and is within language restrictions provided.
\item Search for a clause more general than the bottom clause. This step is done by search-
ing for some subset of the literals in the bottom clause that has the 'best' score.
\item The clause with the best score is added to the current theory and all the examples
made redundant are removed. Return to step 1.
\end{enumerate}

Mode declarations and determinations are used in step 2 of this procedure to bound the hypothesis space. Only predicates that are mentioned in the determinations of the hypothesis and are of the correct type are tried. The bottom clause constructed is the most specific clause that entails the example. Therefore a clause with the same head and any subset of the predicates of the body will be more general than the bottom clause. Aleph only considers these generalisations of this bottom clause. The search space is therefore bounded by $2^n$ with $n$ being the number of predicates in the bottom clause.

By default Aleph preforms a bounded breath first search on all the possible rules, enumerating shorter clauses before longer clauses. The search is bounded by several parameters such as maximum clause size and maximum proof depth. The best score is selected as the one with the best $P - N$ value where $P$ is the number of positive rules entailed by the hypothesis and $N$ is the number of negative rules entailed. For this paper we will use Aleph with the default settings.

\section{ILASP}

ILASP is an ILP system based on Answer Set Programming (ASP). An introduction to ASP can be found here \cite{Corapi/ASP}. ILASP uses a subset of ASP that is defined in these papers\cite{ILASP-Manuel}\cite{MarkLaw/OG-ILASP}\cite{MarkLaw/Thesis} The ILASP process effectively generates all possible rules of a certain length, turns the problem into an ASP problem that adds a predicate to each rule allowing it to be active or inactive. It then uses the ASP solver clingo\cite{Clingo}  to check which rules should be active if the program is to be consistent with the positive and the negation of the negative examples\cite{MarkLaw/OG-ILASP}\cite{MarkLaw/Thesis}. In this paper we use a version of ILASP based on ILASP2i\cite{MarkLaw/ILASP2i} which was developed with the IGGP problem in mind\cite{Cropper/IGGP}. As one input ILASP takes a hypothesis search space, i.e. the set of all hypotheses to be considered. This is constructed using the type signatures given for each problem that are provided in the IGGP dataset.

An ILASP task is defined as a tuple $T = \langle B,S_M,E^+E^-\rangle$ where $B$ is the background knowledge, $S_M$ is the hypothesis space, and $E^+$ and $E^-$ are the positive and negative examples. The ILASP procedure is given in algorithm \ref{alg:ILASP}. 
\begin{algorithm}[H]\label{alg:ILASP}
	\SetAlgoLined
	$n$ = 0\;
	solutions = []\;
	\While{solutions.empty}{
		$S^N$ = all possible hypotheses of length $N$ from $S_M$ \;
		$ns$ = all subsets of $S^N$ that imply $E^-$ (Using an ASP solver)\;
		$vs$ = the set of rules that for each set of rules in $ns$ imply false if exactly those rules are active\;
		solutions = all subsets of $S^N$ that imply $E^+$ and satisfy $vs$ (using asp solver)\;
		$n$ = $n$ + 1\;
	}
	\caption{ILASP outline}
\end{algorithm}

The approaches used by ILASP have proved to be well suited to the IGGP task \cite{Cropper/IGGP}. We expect it to do well in the experiments conducted.
\chapter{Implementations}
\section{Eight Puzzle}
To write an optimal player for Eight Puzzle I decide to use an approach based on best first search.
\subsection{Best first search}
Best first search generates a graph of the game states, expanding the most promising nodes first according to a heuristic for how close to the goal state the current state is. When the goal node is reached the search gives the path from the root node to it, i.e. the list of moves made to get to the goal.
Since Best first search is a well know and often used algorithm in Prolog we decided to use a standard implmentation from Bratko\cite{Bratko}. This decision was made to avoid needless mistakes and inefficiency that would have come with a new independent implementation of this algorithm.

Best First search is a generic algorithm that needs certain problem specific predicates to be implemented for it to function. These predicates are:
\begin{itemize}
\item \textbf{The successor predicate - }\mintinline{Prolog}{s(Node,Node1,Cost)}: This predicate is true if there is an arc costing \mintinline{Prolog}{Cost} between state \mintinline{Prolog}{Node} and state \mintinline{Prolog}{Node1}. In Eight Puzzle we set the cost of all arcs to be 1.
\item \textbf{The Goal predicate - }\mintinline{Prolog}{goal(Node)}: This is true if the state \mintinline{Prolog}{Node} is a goal state.
\item \textbf{The heuristic - }\mintinline{Prolog}{h(Node,H)}: This is a relation that relates a state \mintinline{Prolog}{Node} to a value \mintinline{Prolog}{H} that is a heuristic for how close to the state is to the goal state.
\end{itemize}
To represent the board I decided to use a 9 element list with \mintinline{Prolog}{b} representing the blank tile INSERT IMAGE OF GOAL BOARD \mint{Prolog}{[1,2,3,4,5,6,7,8,b]}.
I defined some useful helper predicates to start with. The Manhatten distance between two tiles between two tiles is the difference in X coordinates plus the difference in Y coordinates, I wrote a predicate to calculate this relation:
\begin{minted}{Prolog}
mandist(X1-Y1,X2-Y2,D) :-
    diff(X1,X2,Dx),
    diff(Y1,Y2,Dy),
    D is Dx+Dy.
\end{minted}
I also wrote predicates to calculate the coordinates of a tile from its position in the list, one that relates two tiles if they are next to each other on the grid and one that gives the position in the list of the blank tile.
\subsubsection{Successor}
To define the successor predicate I decided the best way to do it was to relate two boards by swapping the blank tile with its neighbours. I first wrote a function swap:
\begin{minted}{Prolog}
swap(I,J,L1,L3) :-
   same_length(L1,L3),
   append(BeforeI,[AtI|PastI],L1),
   append(BeforeI,[AtJ|PastI],L2),
   append(BeforeJ,[AtJ|PastJ],L2),
   append(BeforeJ,[AtI|PastJ],L3),
   length(BeforeI,I),
   length(BeforeJ,J).
\end{minted}
This function only uses built in predicates that all do the obvious thing. In the first two appends this rule takes L1 and replaces the element I with the element J to make list L2 then in the second two takes list L2 and replaces J with I to make list L3. The variable AtI and AtJ will be instantiated with the elements at index I and J because of the restriction on the length of the sublist before them at the end of the rule.
The successor function is defined as:
\begin{minted}{Prolog}
s(B1,B2,1) :-
    member(N,B1),
    nth0(NI,B1,N),
    blank_pos(B1,BI),
    neighbor(BI,NI),
    swap(BI,NI,B1,B2).
\end{minted}
Since all arc (move) costs in my version of Eight Puzzle are 1 the predicate is only true when Cost is 1. \mintinline{Prolog}{member(N,B1)} is true when N is a member of B1. Here it restricts N to values on the board. \mintinline{Prolog}{nth0(NI,B1,N)} sets NI to the index of the value N in the list B1, i.e. it tells us the position on the board of the value we are considering. \mintinline{Prolog}{blank_pos(B1,BI)} sets BI to the position on the board of the blank. \mintinline{Prolog}{neighbor(BI,NI)} is true if the positions BI and NI are next to each other on the board. If all of these are true we then instantiate B2 with the new board by swapping the blank and its neighbour.
\subsubsection{Goal}
Defining the goal was actually very simple, I added the predicate: \mint{Prolog}{goal([1,2,3,4,5,6,7,8,b])}
\noindent This is all that is needed to define the goal state.
\subsubsection{Heuristic}
A good heuristic for Eight Puzzle needs to capture an estimate of the distance of the current state from the goal. I initially decided to use the sum of the Manhattan distances of each tile from its position in the goal state. To calculate this I wrote a predicate \mintinline{Prolog}{totdist(L,Goal,N)} which relates a board L, a goal Goal and the sum of the Manhattan distances N.
\begin{minted}{Prolog}
totdist(L,Goal,N) :-
    totdist1(L,Goal,N,0).

totdist1([],_Goal,0,_Pos).

totdist1([b|T],Goal,N,Pos) :-
    !,Pos1 is Pos + 1,
    totdist1(T,Goal,N,Pos1).

totdist1([V|T],Goal,N,Pos) :-
    nth0(I,Goal,V),
    coord(Pos,X1-Y1),
    coord(I,X2-Y2),
    mandist(X1-Y1,X2-Y2,D),
    Pos1 is Pos + 1,
    totdist1(T,Goal,N1,Pos1),
    N is N1 + D.
\end{minted}
My implementation of this predicate iterates through the list working out the Manhattan distance for each tile. When iterating through the list the way to keep track of how far through it you are (the position on the board you are currently looking at) is use a separate variable as a counter. Here I used Pos.
After testing my program with this heuristic I found that it took about 6 seconds to come up with the first solution. I decided that I could probably do better if I had another heuristic that I combined with the Manhattan distance. I decided to use the number of tiles that were out of the row and/or column they were in. I wrote a predicate \mintinline{Prolog}{outofpos(B,Goal,N,Pos)} that relates the board and the goal to the number of tiles out column plus the number of tiles out of row.
\begin{minted}{Prolog}
outofpos([],_Goal,0,_Pos).

outofpos([b|T],Goal,N,Pos) :- !,
    Pos1 is Pos + 1,
    outofpos(T,Goal,N,Pos1).

outofpos([V|T],Goal,N,Pos) :-
    coord(Pos,X1-Y1),
    nth0(PosG,Goal,V),
    coord(PosG,X2-Y2),
    Pos1 is Pos + 1,
    outofpos(T,Goal,N1,Pos1),
    (   xandy(X1 = X2, Y1 = Y2) ->
        N is N1
    ;   xory(X1 = X2, Y1 = Y2) ->
        N is N1 + 1
    ;   N is N1 + 2
    ).

xandy(X,Y) :- X,Y.
xory(X,Y) :- X;Y.
\end{minted}
This predicate iterates through the board and for each tile looks at the place it is on the goal board and checks which coordinates match. If both match then it is the right column and row so the total remains the same, otherwise it is incremented. I eventually found that the heuristic the worked the fastest was Manhattan distance total + 2 * number of tiles out of position. I wrote this predicate for the heuristic:
\begin{minted}{Prolog}
h(B,H) :-
    goal(Goal),
    totdist(B,Goal,D),
    outofpos(B,Goal,N,0),
    H is D + (2*N).
\end{minted}



\input{06-results.tex}

\bibliography{project}
\bibliographystyle{plain}
\end{document}
